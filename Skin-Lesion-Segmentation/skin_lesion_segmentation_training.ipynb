{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce19544",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# PHẦN 1: CÀI ĐẶT, IMPORT VÀ CẤU HÌNH (CHO TRAINING)\n",
    "# --------------------------------------------------------------------\n",
    "print(\">>> [PHẦN 1] Bắt đầu cài đặt thư viện và cấu hình...\")\n",
    "!pip install -q segmentation-models-pytorch albumentations timm scikit-image scikit-learn\n",
    "import os, numpy as np, pandas as pd, cv2, gc, torch, torch.nn as nn, random\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Config:\n",
    "    ARCHITECTURE = 'Unet'\n",
    "    ENCODER = 'efficientnet-b4'\n",
    "    PRETRAINED_WEIGHTS = 'imagenet'\n",
    "    IMAGE_SIZE = 512\n",
    "    N_SPLITS = 5\n",
    "    BATCH_SIZE = 12\n",
    "    EPOCHS = 25\n",
    "    PATIENCE = 5\n",
    "    MIN_DELTA = 1e-4\n",
    "    LEARNING_RATE = 1e-4\n",
    "    GRADIENT_CHECKPOINTING = True\n",
    "    TTA_SCALES = [480, 512, 640]\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    BASE_PATH = \"/kaggle/input/warm-up-program-ai-vietnam-skin-segmentation\"\n",
    "    TRAIN_IMG_PATH = os.path.join(BASE_PATH, \"Train/Train/Image\")\n",
    "    TRAIN_MASK_PATH = os.path.join(BASE_PATH, \"Train/Train/Mask\")\n",
    "    TEST_IMG_PATH = os.path.join(BASE_PATH, \"Test/Test/Image\")\n",
    "    MODEL_OUTPUT_DIR = \"/kaggle/working/models_v8.1/\"\n",
    "\n",
    "cfg = Config()\n",
    "os.makedirs(cfg.MODEL_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8631594",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# PHẦN 2: CÁC HÀM TIỆN ÍCH, LOSS, AUGMENTATION, TTA\n",
    "# --------------------------------------------------------------------\n",
    "def mask2rle(mask):\n",
    "    pixels = mask.flatten(); pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1; runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "class AdvancedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.dice = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "        self.focal = smp.losses.FocalLoss(smp.losses.BINARY_MODE, alpha=0.25, gamma=2.0)\n",
    "        self.tversky = smp.losses.TverskyLoss(smp.losses.BINARY_MODE, alpha=0.7, beta=0.3)\n",
    "    def forward(self, pred, target): return 0.4*self.dice(pred, target) + 0.3*self.focal(pred, target) + 0.3*self.tversky(pred, target)\n",
    "def get_transforms_v8():\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.ShiftScaleRotate(p=0.5),\n",
    "        A.OneOf([A.ElasticTransform(p=0.2), A.GridDistortion(p=0.2)], p=0.3),\n",
    "        A.RandomBrightnessContrast(p=0.5), A.HueSaturationValue(p=0.3), A.CLAHE(p=0.4),\n",
    "        A.OneOf([A.GaussNoise(), A.CoarseDropout(max_holes=8, max_height=32, max_width=32)], p=0.4),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2(),\n",
    "    ])\n",
    "    val_transform = A.Compose([A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()])\n",
    "    return train_transform, val_transform\n",
    "def predict_with_ultimate_tta(models, image_np):\n",
    "    final_predictions = []\n",
    "    for scale in cfg.TTA_SCALES:\n",
    "        transform_scale = A.Compose([A.Resize(scale, scale), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()])\n",
    "        scaled_tensor = transform_scale(image=image_np)['image'].unsqueeze(0).to(cfg.DEVICE)\n",
    "        transforms = [lambda x: x, lambda x: torch.flip(x, [-1]), lambda x: torch.flip(x, [-2]), lambda x: torch.rot90(x, 1, [-2, -1]), lambda x: torch.rot90(x, 3, [-2, -1])]\n",
    "        reverse_transforms = [lambda x: x, lambda x: torch.flip(x, [-1]), lambda x: torch.flip(x, [-2]), lambda x: torch.rot90(x, -1, [-2, -1]), lambda x: torch.rot90(x, -3, [-2, -1])]\n",
    "        tta_preds_for_scale = []\n",
    "        with torch.no_grad(), autocast():\n",
    "            for transform, reverse_transform in zip(transforms, reverse_transforms):\n",
    "                aug_tensor = transform(scaled_tensor)\n",
    "                fold_preds = [torch.sigmoid(model(aug_tensor)) for model in models]\n",
    "                ensembled_pred = torch.stack(fold_preds).mean(0)\n",
    "                tta_preds_for_scale.append(reverse_transform(ensembled_pred))\n",
    "        avg_pred_for_scale = torch.stack(tta_preds_for_scale).mean(0)\n",
    "        restored_pred = F.interpolate(avg_pred_for_scale, size=(512, 512), mode='bilinear', align_corners=False)\n",
    "        final_predictions.append(restored_pred)\n",
    "    return torch.stack(final_predictions).mean(0)\n",
    "def advanced_postprocess(mask, min_size=100):\n",
    "    binary_mask = morphology.remove_small_objects(mask.astype(bool), min_size=min_size)\n",
    "    binary_mask = ndimage.binary_fill_holes(binary_mask)\n",
    "    binary_mask = morphology.binary_closing(binary_mask, morphology.disk(3))\n",
    "    return binary_mask.astype(np.uint8)\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience, self.min_delta, self.counter, self.best_score = patience, min_delta, 0, None\n",
    "        self.best_weights = None\n",
    "    def __call__(self, val_score, model):\n",
    "        if self.best_score is None or val_score > self.best_score + self.min_delta:\n",
    "            self.best_score, self.counter = val_score, 0; self.best_weights = model.state_dict().copy(); return False\n",
    "        else: self.counter += 1; return self.counter >= self.patience\n",
    "class SkinLesionDataset(Dataset):\n",
    "    def __init__(self, ids, img_dir, mask_dir, transform=None):\n",
    "        self.ids, self.img_dir, self.mask_dir, self.transform = ids, img_dir, mask_dir, transform\n",
    "    def __len__(self): return len(self.ids)\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]; img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n",
    "        mask_path = os.path.join(self.mask_dir, f\"{img_id}_segmentation.png\")\n",
    "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        mask = (cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) / 255.0).astype(np.float32)\n",
    "        if self.transform: augmented = self.transform(image=image, mask=mask); image, mask = augmented['image'], augmented['mask']\n",
    "        return image, mask.unsqueeze(0)\n",
    "def dice_coefficient(pred, target, smooth=1e-6):\n",
    "    pred = (pred > 0.5).float(); intersection = (pred * target).sum()\n",
    "    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "def validate_model(model, loader, device):\n",
    "    model.eval(); total_dice = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            with autocast(): preds = torch.sigmoid(model(images))\n",
    "            for pred, mask in zip(preds, masks): total_dice += dice_coefficient(pred, mask).item()\n",
    "    return total_dice / len(loader.dataset)\n",
    "def train_one_epoch(model, loader, optimizer, scheduler, loss_fn, scaler, device):\n",
    "    model.train(); total_loss = 0\n",
    "    for images, masks in loader:\n",
    "        images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(): loss = loss_fn(model(images), masks)\n",
    "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "        if scheduler is not None: scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "def create_model():\n",
    "    model = smp.Unet(encoder_name=cfg.ENCODER, encoder_weights=cfg.PRETRAINED_WEIGHTS, in_channels=3, classes=1, activation=None)\n",
    "    if cfg.GRADIENT_CHECKPOINTING:\n",
    "        try:\n",
    "            if hasattr(model.encoder, 'set_grad_checkpointing'): model.encoder.set_grad_checkpointing(enable=True); print(\"Gradient checkpointing enabled.\")\n",
    "        except Exception as e: print(f\"Không thể kích hoạt gradient checkpointing: {e}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877680a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# PHẦN 3: PIPELINE HUẤN LUYỆN K-FOLD\n",
    "# --------------------------------------------------------------------\n",
    "print(\">>> [PHẦN 3] Bắt đầu pipeline huấn luyện K-Fold...\")\n",
    "START_FOLD = 0 \n",
    "all_files = [f for f in os.listdir(cfg.TRAIN_IMG_PATH) if f.endswith('.jpg')]\n",
    "all_ids = [os.path.splitext(f)[0] for f in all_files]\n",
    "kf = KFold(n_splits=cfg.N_SPLITS, shuffle=True, random_state=42)\n",
    "train_transform, val_transform = get_transforms_v8()\n",
    "full_dataset = SkinLesionDataset(all_ids, cfg.TRAIN_IMG_PATH, cfg.TRAIN_MASK_PATH, transform=train_transform)\n",
    "val_dataset_template = SkinLesionDataset(all_ids, cfg.TRAIN_IMG_PATH, cfg.TRAIN_MASK_PATH, transform=val_transform)\n",
    "overall_val_dice = 0.0\n",
    "all_splits = list(kf.split(all_ids))\n",
    "for fold in range(START_FOLD, cfg.N_SPLITS):\n",
    "    print(f\"\\n{'='*25} FOLD {fold+1}/{cfg.N_SPLITS} {'='*25}\")\n",
    "    train_idx, val_idx = all_splits[fold]\n",
    "    train_subset, val_subset = Subset(full_dataset, train_idx), Subset(val_dataset_template, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=cfg.BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    model = create_model().to(cfg.DEVICE)\n",
    "    loss_fn = AdvancedLoss().to(cfg.DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=cfg.LEARNING_RATE*5, epochs=cfg.EPOCHS, steps_per_epoch=len(train_loader))\n",
    "    scaler = GradScaler()\n",
    "    early_stopper = EarlyStopping(patience=cfg.PATIENCE, min_delta=cfg.MIN_DELTA)\n",
    "    for epoch in range(1, cfg.EPOCHS + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, loss_fn, scaler, cfg.DEVICE)\n",
    "        val_dice = validate_model(model, val_loader, cfg.DEVICE)\n",
    "        print(f\"Fold {fold+1} Epoch {epoch}: Train Loss: {train_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
    "        if early_stopper(val_dice, model): print(f\"⏰ Early stopping! Best Dice: {early_stopper.best_score:.4f}\"); break\n",
    "    model.load_state_dict(early_stopper.best_weights)\n",
    "    torch.save(model.state_dict(), os.path.join(cfg.MODEL_OUTPUT_DIR, f\"best_model_fold_{fold+1}.pth\"))\n",
    "    print(f\"Đã lưu model tốt nhất cho Fold {fold+1} với Dice: {early_stopper.best_score:.4f}\")\n",
    "    overall_val_dice += early_stopper.best_score\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "print(f\"\\nTraining K-Fold V8.1 hoàn tất! Điểm Dice trung bình: {overall_val_dice/cfg.N_SPLITS:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd007eed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# PHẦN 4: PIPELINE SUY LUẬN\n",
    "# --------------------------------------------------------------------\n",
    "print(\"\\n>>> [PHẦN 4] Bắt đầu pipeline suy luận...\")\n",
    "fold_models = []\n",
    "for fold in range(1, cfg.N_SPLITS + 1):\n",
    "    model_path = os.path.join(cfg.MODEL_OUTPUT_DIR, f\"best_model_fold_{fold}.pth\")\n",
    "    if os.path.exists(model_path):\n",
    "        model = create_model().to(cfg.DEVICE)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval(); fold_models.append(model)\n",
    "if fold_models:\n",
    "    test_files = [f for f in os.listdir(cfg.TEST_IMG_PATH) if f.endswith('.jpg')]\n",
    "    test_ids = [os.path.splitext(f)[0] for f in test_files]\n",
    "    results_v8 = []\n",
    "    OPTIMAL_THRESHOLD = 0.6\n",
    "    for test_id in tqdm(test_ids, desc=\"Ultimate Inference V8.3\"):\n",
    "        img_path = os.path.join(cfg.TEST_IMG_PATH, f\"{test_id}.jpg\")\n",
    "        image_numpy = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        final_pred_tensor = predict_with_ultimate_tta(fold_models, image_numpy)\n",
    "        final_mask_np = final_pred_tensor.cpu().numpy().squeeze()\n",
    "        binary_mask_with_threshold = (final_mask_np > OPTIMAL_THRESHOLD)\n",
    "        final_mask_processed = advanced_postprocess(binary_mask_with_threshold)\n",
    "        rle = mask2rle(final_mask_processed)\n",
    "        results_v8.append({\"ID\": f\"{test_id}_segmentation\", \"Predicted_Mask\": rle})\n",
    "    submission_df_v8 = pd.DataFrame(results_v8)\n",
    "    submission_filename = f\"submission_v8.3_ultimateTTA_thresh{OPTIMAL_THRESHOLD}.csv\"\n",
    "    submission_df_v8.to_csv(submission_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
