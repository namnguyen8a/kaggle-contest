# **PhÃ¢n vÃ¹ng Tá»•n thÆ°Æ¡ng Da - [AIMA Challenge]**

**Káº¿t quáº£ tá»‘t nháº¥t trÃªn Public Leaderboard: 0.91557**

## **1. Tá»•ng quan vá» Cuá»™c thi & Dá»¯ liá»‡u**

-   **Nhiá»‡m vá»¥:** Binary Semantic Segmentation. XÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh TrÃ­ tuá»‡ NhÃ¢n táº¡o Ä‘á»ƒ táº¡o ra máº·t náº¡ (mask) nhá»‹ phÃ¢n, trong Ä‘Ã³ pixel mÃ u tráº¯ng Ä‘Ã¡nh dáº¥u vÃ¹ng tá»•n thÆ°Æ¡ng vÃ  pixel mÃ u Ä‘en lÃ  da lÃ nh.
-   **Dá»¯ liá»‡u:**
    -   **Train:** 2595 áº£nh da liá»…u (.jpg) vÃ  máº·t náº¡ tÆ°Æ¡ng á»©ng (.png) vá»›i nhiá»u Ä‘á»™ phÃ¢n giáº£i khÃ¡c nhau.
    -   **Test:** 1100 áº£nh khÃ´ng cÃ³ nhÃ£n.
-   **ThÆ°á»›c Ä‘o:** Dice Coefficient (Dice Score).
-   **Äá»‹nh dáº¡ng ná»™p bÃ i:** Run-Length Encoding (RLE) cá»§a mask dá»± Ä‘oÃ¡n, sau khi Ä‘Ã£ Ä‘Æ°á»£c resize vá» kÃ­ch thÆ°á»›c 512x512.

## **2. PhÆ°Æ¡ng phÃ¡p luáº­n Chung**

ToÃ n bá»™ quÃ¡ trÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn má»™t phÆ°Æ¡ng phÃ¡p luáº­n láº·p Ä‘i láº·p láº¡i: **Thá»­ nghiá»‡m -> PhÃ¢n tÃ­ch -> Cáº£i tiáº¿n**. Chiáº¿n lÆ°á»£c cá»‘t lÃµi Ä‘Ã£ chá»©ng minh hiá»‡u quáº£ bao gá»“m:

1.  **K-Fold Cross-Validation:** Thay vÃ¬ chá»‰ chia dá»¯ liá»‡u má»™t láº§n, toÃ n bá»™ táº­p train Ä‘Æ°á»£c chia thÃ nh 5 pháº§n (folds). QuÃ¡ trÃ¬nh training Ä‘Æ°á»£c láº·p láº¡i 5 láº§n, má»—i láº§n sá»­ dá»¥ng 4 pháº§n Ä‘á»ƒ huáº¥n luyá»‡n vÃ  1 pháº§n Ä‘á»ƒ kiá»ƒm tra. Äiá»u nÃ y giÃºp táº­n dá»¥ng tá»‘i Ä‘a dá»¯ liá»‡u vÃ  táº¡o ra cÃ¡c mÃ´ hÃ¬nh máº¡nh máº½, á»•n Ä‘á»‹nh.
2.  **Ensemble Learning:** Káº¿t quáº£ cuá»‘i cÃ¹ng khÃ´ng dá»±a trÃªn má»™t mÃ´ hÃ¬nh duy nháº¥t. Thay vÃ o Ä‘Ã³, cÃ¡c mÃ´ hÃ¬nh tá»‘t nháº¥t tá»« má»—i fold Ä‘Æ°á»£c káº¿t há»£p láº¡i (báº±ng cÃ¡ch láº¥y trung bÃ¬nh dá»± Ä‘oÃ¡n) Ä‘á»ƒ táº¡o ra má»™t quyáº¿t Ä‘á»‹nh tá»•ng há»£p, giÃºp giáº£m lá»—i vÃ  tÄƒng Ä‘á»™ chÃ­nh xÃ¡c.
3.  **Test Time Augmentation (TTA):** á» khÃ¢u dá»± Ä‘oÃ¡n, khÃ´ng chá»‰ áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng. Nhiá»u phiÃªn báº£n biáº¿n Ä‘á»•i cá»§a áº£nh test (láº­t, xoay, thay Ä‘á»•i kÃ­ch thÆ°á»›c) Ä‘Æ°á»£c Ä‘Æ°a vÃ o mÃ´ hÃ¬nh. Káº¿t quáº£ tá»« táº¥t cáº£ cÃ¡c phiÃªn báº£n nÃ y Ä‘Æ°á»£c tá»•ng há»£p láº¡i Ä‘á»ƒ táº¡o ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng, cá»±c ká»³ máº¡nh máº½ vÃ  á»•n Ä‘á»‹nh.
---

## **3. Hai Giáº£i phÃ¡p Tá»‘t nháº¥t Ä‘Æ°á»£c chá»n cho Private Leaderboard**

DÆ°á»›i Ä‘Ã¢y lÃ  mÃ´ táº£ chi tiáº¿t vá» hai submission Ä‘Ã£ Ä‘Æ°á»£c chá»n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng trÃªn táº­p dá»¯ liá»‡u áº©n.

### **Submission 1: `submission_V-FINAL_GrandEnsemble_thresh0.6.csv`**

-   **Public Score:** **0.91557**
-   **Private Score:** `0.89965`

#### **A. PhÃ¢n tÃ­ch Chi tiáº¿t HÆ°á»›ng tiáº¿p cáº­n**

ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p **"Grand Ensemble"**, káº¿t há»£p 10 model tá»« 2 phiÃªn báº£n training khÃ¡c nhau (V8.1 vÃ  V9.1).

1.  **Bá»™ Model 1 (Tá»« V8.1): 5 model `Unet` vá»›i backbone `EfficientNet-B4`.**
    -   ÄÆ°á»£c huáº¥n luyá»‡n á»Ÿ kÃ­ch thÆ°á»›c 512x512, `EPOCHS=25`, `BATCH_SIZE=12`.
    -   Sá»­ dá»¥ng `AdvancedLoss` (Dice+Focal+Tversky).
    -   ÄÃ£ chá»©ng tá» sá»± á»•n Ä‘á»‹nh vÃ  hiá»‡u nÄƒng cao.
2.  **Bá»™ Model 2 (Tá»« V9.1): 5 model `UnetPlusPlus` vá»›i backbone `timm-efficientnet-b5`.**
    -   ÄÆ°á»£c huáº¥n luyá»‡n á»Ÿ kÃ­ch thÆ°á»›c 512x512, `EPOCHS=20`, `BATCH_SIZE=6`.
    -   Sá»­ dá»¥ng kiáº¿n trÃºc `Unet++` tiÃªn tiáº¿n hÆ¡n vÃ  backbone `B5` máº¡nh máº½ hÆ¡n.
3.  **Chiáº¿n lÆ°á»£c Suy luáº­n:**
    -   **Ultimate TTA:** Ãp dá»¥ng TTA Ä‘a kÃ­ch thÆ°á»›c vÃ  Ä‘a biáº¿n thá»ƒ (`Multi-Scale` & `Multi-Transform`) cho **tá»«ng bá»™ model riÃªng biá»‡t**.
    -   **Grand Ensemble:** Láº¥y káº¿t quáº£ cuá»‘i cÃ¹ng cá»§a bá»™ model V8 vÃ  V9, sau Ä‘Ã³ **láº¥y trung bÃ¬nh cá»™ng** má»™t láº§n ná»¯a Ä‘á»ƒ ra quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng.
    -   **Thresholding & Post-processing:** Sá»­ dá»¥ng ngÆ°á»¡ng tá»‘i Æ°u `0.6` vÃ  cÃ¡c ká»¹ thuáº­t háº­u xá»­ lÃ½ (lÃ m má»‹n, láº¥p lá»—, xÃ³a nhiá»…u).

#### **B. MÃ£ nguá»“n Tham chiáº¿u (Grand Ensemble)**
<details>
<summary>Click Ä‘á»ƒ xem MÃ£ nguá»“n Suy luáº­n Grand Ensemble</summary>

```python
# ====================================================================
# SKIN SEGMENTATION V-FINAL - GRAND ENSEMBLE (V8 + V9)
# ====================================================================
# PHáº¦N 1: CÃ€I Äáº¶T, IMPORT VÃ€ Cáº¤U HÃŒNH
print(">>> [PHáº¦N 1] Báº¯t Ä‘áº§u cÃ i Ä‘áº·t...")
!pip install -q segmentation-models-pytorch albumentations timm scikit-image scikit-learn
import os, numpy as np, pandas as pd, cv2, torch, torch.nn as nn
from tqdm import tqdm
from torch.cuda.amp import autocast
import torch.nn.functional as F
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
from scipy import ndimage
from skimage import morphology
import warnings
warnings.filterwarnings('ignore')

class Config:
    IMAGE_SIZE = 512
    N_SPLITS = 5
    TTA_SCALES = [480, 512, 640]
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    DATASET_PATH = "/kaggle/input/warm-up-program-ai-vietnam-skin-segmentation"
    TEST_IMG_PATH = os.path.join(DATASET_PATH, "Test/Test/Image")
    
    # Cáº§n cáº­p nháº­t cÃ¡c Ä‘Æ°á»ng dáº«n nÃ y cho Ä‘Ãºng vá»›i output notebooks cá»§a báº¡n
    MODEL_V8_DIR = "/kaggle/input/best-model-5-fold-v8"
    MODEL_V9_DIR = "/kaggle/input/best-model-v9"
    
    V8_CONFIG = {'arch': 'Unet', 'encoder': 'efficientnet-b4'}
    V9_CONFIG = {'arch': 'UnetPlusPlus', 'encoder': 'timm-efficientnet-b5'}
cfg = Config()

# PHáº¦N 2: CÃC HÃ€M TIá»†N ÃCH
def mask2rle(mask):
    pixels = mask.flatten(); pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1; runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)
def create_model(arch, encoder):
    return smp.create_model(arch, encoder_name=encoder, encoder_weights='imagenet', in_channels=3, classes=1)
def predict_with_ultimate_tta(models, image_np):
    final_predictions = []
    for scale in cfg.TTA_SCALES:
        transform_scale = A.Compose([A.Resize(scale, scale), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()])
        scaled_tensor = transform_scale(image=image_np)['image'].unsqueeze(0).to(cfg.DEVICE)
        transforms = [lambda x: x, lambda x: torch.flip(x, [-1]), lambda x: torch.flip(x, [-2]), lambda x: torch.rot90(x, 1, [-2, -1]), lambda x: torch.rot90(x, 3, [-2, -1])]
        reverse_transforms = [lambda x: x, lambda x: torch.flip(x, [-1]), lambda x: torch.flip(x, [-2]), lambda x: torch.rot90(x, -1, [-2, -1]), lambda x: torch.rot90(x, -3, [-2, -1])]
        tta_preds_for_scale = []
        with torch.no_grad(), autocast():
            for transform, reverse_transform in zip(transforms, reverse_transforms):
                aug_tensor = transform(scaled_tensor)
                fold_preds = [torch.sigmoid(model(aug_tensor)) for model in models]
                ensembled_pred = torch.stack(fold_preds).mean(0)
                tta_preds_for_scale.append(reverse_transform(ensembled_pred))
        avg_pred_for_scale = torch.stack(tta_preds_for_scale).mean(0)
        restored_pred = F.interpolate(avg_pred_for_scale, size=(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), mode='bilinear', align_corners=False)
        final_predictions.append(restored_pred)
    return torch.stack(final_predictions).mean(0)
def advanced_postprocess(mask, min_size=100):
    binary_mask = morphology.remove_small_objects(mask.astype(bool), min_size=min_size)
    binary_mask = ndimage.binary_fill_holes(binary_mask)
    binary_mask = morphology.binary_closing(binary_mask, morphology.disk(3))
    return binary_mask.astype(np.uint8)

# PHáº¦N 3: PIPELINE SUY LUáº¬N "GRAND ENSEMBLE"
models_v8 = []
for fold in range(1, cfg.N_SPLITS + 1):
    model = create_model(cfg.V8_CONFIG['arch'], cfg.V8_CONFIG['encoder']).to(cfg.DEVICE)
    model.load_state_dict(torch.load(os.path.join(cfg.MODEL_V8_DIR, f"best_model_fold_{fold}.pth")))
    model.eval(); models_v8.append(model)
print(f"âœ… ÄÃ£ táº£i thÃ nh cÃ´ng {len(models_v8)} models V8.")
models_v9 = []
for fold in range(1, cfg.N_SPLITS + 1):
    model = create_model(cfg.V9_CONFIG['arch'], cfg.V9_CONFIG['encoder']).to(cfg.DEVICE)
    model.load_state_dict(torch.load(os.path.join(cfg.MODEL_V9_DIR, f"best_model_fold_{fold}.pth")))
    model.eval(); models_v9.append(model)
print(f"âœ… ÄÃ£ táº£i thÃ nh cÃ´ng {len(models_v9)} models V9.")
test_files = [f for f in os.listdir(cfg.TEST_IMG_PATH) if f.endswith('.jpg')]
test_ids = [os.path.splitext(f)[0] for f in test_files]
results = []
OPTIMAL_THRESHOLD = 0.6
for test_id in tqdm(test_ids, desc=f"Grand Ensemble Inference"):
    img_path = os.path.join(cfg.TEST_IMG_PATH, f"{test_id}.jpg")
    image_numpy = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)
    pred_v8 = predict_with_ultimate_tta(models_v8, image_numpy)
    pred_v9 = predict_with_ultimate_tta(models_v9, image_numpy)
    final_pred_tensor = (pred_v8 + pred_v9) / 2.0
    final_mask_np = final_pred_tensor.cpu().numpy().squeeze()
    binary_mask_with_threshold = (final_mask_np > OPTIMAL_THRESHOLD)
    final_mask_processed = advanced_postprocess(binary_mask_with_threshold)
    rle = mask2rle(final_mask_processed)
    results.append({"ID": f"{test_id}_segmentation", "Predicted_Mask": rle})
submission_df = pd.DataFrame(results)
submission_filename = f"submission_V-FINAL_GrandEnsemble_thresh{OPTIMAL_THRESHOLD}.csv"
submission_df.to_csv(submission_filename, index=False)
```

</details>

---

### **Submission 2: `submission_v8.3_ultimateTTA_thresh0.6.csv`**

-   **Public Score:** **0.91447**
-   **Private Score:** `0.90117`
#### **A. PhÃ¢n tÃ­ch Chi tiáº¿t HÆ°á»›ng tiáº¿p cáº­n**

1.  **Bá»™ Model (Tá»« V8.1):** Sá»­ dá»¥ng 5 model `Unet` vá»›i backbone `EfficientNet-B4`. ÄÃ¢y lÃ  bá»™ model Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i cÃ¡c thÃ´ng sá»‘ cÃ¢n báº±ng, Ä‘áº£m báº£o hoÃ n thÃ nh trong thá»i gian cho phÃ©p vÃ  cÃ³ cháº¥t lÆ°á»£ng cao.
2.  **Chiáº¿n lÆ°á»£c Suy luáº­n (Ultimate TTA):**
    -   **Ensemble:** Tá»• há»£p káº¿t quáº£ tá»« 5 model Ä‘Ã£ huáº¥n luyá»‡n.
    -   **Multi-Scale & Multi-Transform TTA:** Má»—i áº£nh test Ä‘Æ°á»£c dá»± Ä‘oÃ¡n 15 láº§n (`3 scales * 5 transforms`), vÃ  má»—i láº§n dá»± Ä‘oÃ¡n láº¡i lÃ  káº¿t quáº£ ensemble cá»§a 5 model. Ká»¹ thuáº­t nÃ y giÃºp mÃ´ hÃ¬nh "nhÃ¬n" áº£nh á»Ÿ nhiá»u bá»‘i cáº£nh vÃ  gÃ³c Ä‘á»™ khÃ¡c nhau, táº¡o ra má»™t dá»± Ä‘oÃ¡n tá»•ng há»£p cá»±c ká»³ máº¡nh máº½.
    -   **Thresholding & Post-processing:** Sá»­ dá»¥ng ngÆ°á»¡ng `0.6` vÃ  cÃ¡c ká»¹ thuáº­t háº­u xá»­ lÃ½.

#### **B. MÃ£ nguá»“n Tham chiáº¿u**

<details>
<summary>Click Ä‘á»ƒ xem MÃ£ nguá»“n PhiÃªn báº£n 8</summary>

```python
# ====================================================================
# SKIN SEGMENTATION V8.1 (TRAINING) & V8.3 (INFERENCE)
# ====================================================================

# --------------------------------------------------------------------
# PHáº¦N 1: CÃ€I Äáº¶T, IMPORT VÃ€ Cáº¤U HÃŒNH (CHO TRAINING)
# --------------------------------------------------------------------
print(">>> [PHáº¦N 1] Báº¯t Ä‘áº§u cÃ i Ä‘áº·t thÆ° viá»‡n vÃ  cáº¥u hÃ¬nh...")
!pip install -q segmentation-models-pytorch albumentations timm scikit-image scikit-learn
import os, numpy as np, pandas as pd, cv2, gc, torch, torch.nn as nn, random
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader, Subset
from torch.cuda.amp import autocast, GradScaler
import torch.nn.functional as F
from sklearn.model_selection import KFold
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
from scipy import ndimage
from skimage import morphology
import warnings
warnings.filterwarnings('ignore')

class Config:
    ARCHITECTURE = 'Unet'
    ENCODER = 'efficientnet-b4'
    PRETRAINED_WEIGHTS = 'imagenet'
    IMAGE_SIZE = 512
    N_SPLITS = 5
    BATCH_SIZE = 12
    EPOCHS = 25
    PATIENCE = 5
    MIN_DELTA = 1e-4
    LEARNING_RATE = 1e-4
    GRADIENT_CHECKPOINTING = True
    TTA_SCALES = [480, 512, 640]
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    BASE_PATH = "/kaggle/input/warm-up-program-ai-vietnam-skin-segmentation"
    TRAIN_IMG_PATH = os.path.join(BASE_PATH, "Train/Train/Image")
    TRAIN_MASK_PATH = os.path.join(BASE_PATH, "Train/Train/Mask")
    TEST_IMG_PATH = os.path.join(BASE_PATH, "Test/Test/Image")
    MODEL_OUTPUT_DIR = "/kaggle/working/models_v8.1/"

cfg = Config()
os.makedirs(cfg.MODEL_OUTPUT_DIR, exist_ok=True)

# --------------------------------------------------------------------
# PHáº¦N 2: CÃC HÃ€M TIá»†N ÃCH, LOSS, AUGMENTATION, TTA
# --------------------------------------------------------------------
def mask2rle(mask):
    pixels = mask.flatten(); pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1; runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)
class AdvancedLoss(nn.Module):
    def __init__(self):
        super().__init__(); self.dice = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)
        self.focal = smp.losses.FocalLoss(smp.losses.BINARY_MODE, alpha=0.25, gamma=2.0)
        self.tversky = smp.losses.TverskyLoss(smp.losses.BINARY_MODE, alpha=0.7, beta=0.3)
    def forward(self, pred, target): return 0.4*self.dice(pred, target) + 0.3*self.focal(pred, target) + 0.3*self.tversky(pred, target)
def get_transforms_v8():
    train_transform = A.Compose([
        A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.ShiftScaleRotate(p=0.5),
        A.OneOf([A.ElasticTransform(p=0.2), A.GridDistortion(p=0.2)], p=0.3),
        A.RandomBrightnessContrast(p=0.5), A.HueSaturationValue(p=0.3), A.CLAHE(p=0.4),
        A.OneOf([A.GaussNoise(), A.CoarseDropout(max_holes=8, max_height=32, max_width=32)], p=0.4),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2(),
    ])
    val_transform = A.Compose([A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()])
    return train_transform, val_transform
def predict_with_ultimate_tta(models, image_np):
    final_predictions = []
    for scale in cfg.TTA_SCALES:
        transform_scale = A.Compose([A.Resize(scale, scale), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()])
        scaled_tensor = transform_scale(image=image_np)['image'].unsqueeze(0).to(cfg.DEVICE)
        transforms = [lambda x: x, lambda x: torch.flip(x, [-1]), lambda x: torch.flip(x, [-2]), lambda x: torch.rot90(x, 1, [-2, -1]), lambda x: torch.rot90(x, 3, [-2, -1])]
        reverse_transforms = [lambda x: x, lambda x: torch.flip(x, [-1]), lambda x: torch.flip(x, [-2]), lambda x: torch.rot90(x, -1, [-2, -1]), lambda x: torch.rot90(x, -3, [-2, -1])]
        tta_preds_for_scale = []
        with torch.no_grad(), autocast():
            for transform, reverse_transform in zip(transforms, reverse_transforms):
                aug_tensor = transform(scaled_tensor)
                fold_preds = [torch.sigmoid(model(aug_tensor)) for model in models]
                ensembled_pred = torch.stack(fold_preds).mean(0)
                tta_preds_for_scale.append(reverse_transform(ensembled_pred))
        avg_pred_for_scale = torch.stack(tta_preds_for_scale).mean(0)
        restored_pred = F.interpolate(avg_pred_for_scale, size=(512, 512), mode='bilinear', align_corners=False)
        final_predictions.append(restored_pred)
    return torch.stack(final_predictions).mean(0)
def advanced_postprocess(mask, min_size=100):
    binary_mask = morphology.remove_small_objects(mask.astype(bool), min_size=min_size)
    binary_mask = ndimage.binary_fill_holes(binary_mask)
    binary_mask = morphology.binary_closing(binary_mask, morphology.disk(3))
    return binary_mask.astype(np.uint8)
class EarlyStopping:
    def __init__(self, patience=7, min_delta=0):
        self.patience, self.min_delta, self.counter, self.best_score = patience, min_delta, 0, None
        self.best_weights = None
    def __call__(self, val_score, model):
        if self.best_score is None or val_score > self.best_score + self.min_delta:
            self.best_score, self.counter = val_score, 0; self.best_weights = model.state_dict().copy(); return False
        else: self.counter += 1; return self.counter >= self.patience
class SkinLesionDataset(Dataset):
    def __init__(self, ids, img_dir, mask_dir, transform=None):
        self.ids, self.img_dir, self.mask_dir, self.transform = ids, img_dir, mask_dir, transform
    def __len__(self): return len(self.ids)
    def __getitem__(self, idx):
        img_id = self.ids[idx]; img_path = os.path.join(self.img_dir, f"{img_id}.jpg")
        mask_path = os.path.join(self.mask_dir, f"{img_id}_segmentation.png")
        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)
        mask = (cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) / 255.0).astype(np.float32)
        if self.transform: augmented = self.transform(image=image, mask=mask); image, mask = augmented['image'], augmented['mask']
        return image, mask.unsqueeze(0)
def dice_coefficient(pred, target, smooth=1e-6):
    pred = (pred > 0.5).float(); intersection = (pred * target).sum()
    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
def validate_model(model, loader, device):
    model.eval(); total_dice = 0
    with torch.no_grad():
        for images, masks in loader:
            images, masks = images.to(device), masks.to(device)
            with autocast(): preds = torch.sigmoid(model(images))
            for pred, mask in zip(preds, masks): total_dice += dice_coefficient(pred, mask).item()
    return total_dice / len(loader.dataset)
def train_one_epoch(model, loader, optimizer, scheduler, loss_fn, scaler, device):
    model.train(); total_loss = 0
    for images, masks in loader:
        images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)
        optimizer.zero_grad()
        with autocast(): loss = loss_fn(model(images), masks)
        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()
        if scheduler is not None: scheduler.step()
        total_loss += loss.item()
    return total_loss / len(loader)
def create_model():
    model = smp.Unet(encoder_name=cfg.ENCODER, encoder_weights=cfg.PRETRAINED_WEIGHTS, in_channels=3, classes=1, activation=None)
    if cfg.GRADIENT_CHECKPOINTING:
        try:
            if hasattr(model.encoder, 'set_grad_checkpointing'): model.encoder.set_grad_checkpointing(enable=True); print("âœ… Gradient checkpointing enabled.")
        except Exception as e: print(f"âš ï¸ KhÃ´ng thá»ƒ kÃ­ch hoáº¡t gradient checkpointing: {e}")
    return model

# --------------------------------------------------------------------
# PHáº¦N 3: PIPELINE HUáº¤N LUYá»†N K-FOLD
# --------------------------------------------------------------------
print(">>> [PHáº¦N 3] Báº¯t Ä‘áº§u pipeline huáº¥n luyá»‡n K-Fold...")
START_FOLD = 0 
all_files = [f for f in os.listdir(cfg.TRAIN_IMG_PATH) if f.endswith('.jpg')]
all_ids = [os.path.splitext(f)[0] for f in all_files]
kf = KFold(n_splits=cfg.N_SPLITS, shuffle=True, random_state=42)
train_transform, val_transform = get_transforms_v8()
full_dataset = SkinLesionDataset(all_ids, cfg.TRAIN_IMG_PATH, cfg.TRAIN_MASK_PATH, transform=train_transform)
val_dataset_template = SkinLesionDataset(all_ids, cfg.TRAIN_IMG_PATH, cfg.TRAIN_MASK_PATH, transform=val_transform)
overall_val_dice = 0.0
all_splits = list(kf.split(all_ids))
for fold in range(START_FOLD, cfg.N_SPLITS):
    print(f"\n{'='*25} FOLD {fold+1}/{cfg.N_SPLITS} {'='*25}")
    train_idx, val_idx = all_splits[fold]
    train_subset, val_subset = Subset(full_dataset, train_idx), Subset(val_dataset_template, val_idx)
    train_loader = DataLoader(train_subset, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)
    val_loader = DataLoader(val_subset, batch_size=cfg.BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)
    model = create_model().to(cfg.DEVICE)
    loss_fn = AdvancedLoss().to(cfg.DEVICE)
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE)
    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=cfg.LEARNING_RATE*5, epochs=cfg.EPOCHS, steps_per_epoch=len(train_loader))
    scaler = GradScaler()
    early_stopper = EarlyStopping(patience=cfg.PATIENCE, min_delta=cfg.MIN_DELTA)
    for epoch in range(1, cfg.EPOCHS + 1):
        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, loss_fn, scaler, cfg.DEVICE)
        val_dice = validate_model(model, val_loader, cfg.DEVICE)
        print(f"Fold {fold+1} Epoch {epoch}: Train Loss: {train_loss:.4f} | Val Dice: {val_dice:.4f}")
        if early_stopper(val_dice, model): print(f"â° Early stopping! Best Dice: {early_stopper.best_score:.4f}"); break
    model.load_state_dict(early_stopper.best_weights)
    torch.save(model.state_dict(), os.path.join(cfg.MODEL_OUTPUT_DIR, f"best_model_fold_{fold+1}.pth"))
    print(f"ğŸ‰ ÄÃ£ lÆ°u model tá»‘t nháº¥t cho Fold {fold+1} vá»›i Dice: {early_stopper.best_score:.4f}")
    overall_val_dice += early_stopper.best_score
    gc.collect(); torch.cuda.empty_cache()
print(f"\nâœ… Training K-Fold V8.1 hoÃ n táº¥t! Äiá»ƒm Dice trung bÃ¬nh: {overall_val_dice/cfg.N_SPLITS:.4f}")

# --------------------------------------------------------------------
# PHáº¦N 4: PIPELINE SUY LUáº¬N Tá»I THÆ¯á»¢NG (TÆ¯Æ NG ÄÆ¯Æ NG V8.3)
# --------------------------------------------------------------------
print("\n>>> [PHáº¦N 4] Báº¯t Ä‘áº§u pipeline suy luáº­n tá»‘i thÆ°á»£ng...")
fold_models = []
for fold in range(1, cfg.N_SPLITS + 1):
    model_path = os.path.join(cfg.MODEL_OUTPUT_DIR, f"best_model_fold_{fold}.pth")
    if os.path.exists(model_path):
        model = create_model().to(cfg.DEVICE)
        model.load_state_dict(torch.load(model_path))
        model.eval(); fold_models.append(model)
if fold_models:
    test_files = [f for f in os.listdir(cfg.TEST_IMG_PATH) if f.endswith('.jpg')]
    test_ids = [os.path.splitext(f)[0] for f in test_files]
    results_v8 = []
    OPTIMAL_THRESHOLD = 0.6
    for test_id in tqdm(test_ids, desc="Ultimate Inference V8.3"):
        img_path = os.path.join(cfg.TEST_IMG_PATH, f"{test_id}.jpg")
        image_numpy = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)
        final_pred_tensor = predict_with_ultimate_tta(fold_models, image_numpy)
        final_mask_np = final_pred_tensor.cpu().numpy().squeeze()
        binary_mask_with_threshold = (final_mask_np > OPTIMAL_THRESHOLD)
        final_mask_processed = advanced_postprocess(binary_mask_with_threshold)
        rle = mask2rle(final_mask_processed)
        results_v8.append({"ID": f"{test_id}_segmentation", "Predicted_Mask": rle})
    submission_df_v8 = pd.DataFrame(results_v8)
    submission_filename = f"submission_v8.3_ultimateTTA_thresh{OPTIMAL_THRESHOLD}.csv"
    submission_df_v8.to_csv(submission_filename, index=False)
```

</details>